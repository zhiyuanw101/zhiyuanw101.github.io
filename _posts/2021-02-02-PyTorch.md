---
layout: post
title: PyTorch
categories: [Python, Wiki, Utils]
description: PyTorch
keywords: Python, Wiki, Utils
---

## Basics

### `torch.Tensor`

#### Creation

```python
# by shape
shape = (3,4)
t0_1 = torch.ones(shape)
t0 = torch.rand(3,4)
t1 = torch.zeros(3,4)
t2 = torch.ones(3,4)

# from NumPy
t3 = torch.from_numpy(np.random.rand(3,4))

# from array
data = [[1, 2],[3, 4]]
x_data = torch.tensor(data)

# from other Tensor
tensor = torch.ones_like(x_data)
```

#### Attributes

- `tensor.shape`
- `tensor.dtype`
- `tensor.device`

#### Operations

##### In-place operations

operations with suffix `_`

- `x.copy_(y)`
- `x.t_()`
- `x.add_()`

##### Other operations similar to numpy

### `torch.nn.Module`

- Neural network module
- `torch.nn.functional` uses a functional (stateless) approach., `torch.nn.Module` defined as class, internally will call the functional counterpart in `functional`

### `torch.autograd`

### `torch.optim`

### Basic steps

1. define network:
   1. `net.forward()`
2. define loss:
   1. `prediction = net(input)`forward the prediction
   2. calculate [loss](https://pytorch.org/docs/nn.html#loss-functions) with prediction and labels
3. backprop:
   1. `net.zero_grad()`: clear previous gradient
   2. `loss.backword()`: calculate gradient at every node
4. update parameters:
   1. `for f in net.parameters():` update each parameter using `f.grad`
   2. or use provided [optimizer](https://pytorch.org/docs/stable/optim.html).